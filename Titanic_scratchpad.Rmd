---
title: "This is just the scratchpad for the analysis not the final report"
author: "Ozan Aygun"
date: "5/7/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results = "markup", fig.align = "center",
                      fig.width = 5, fig.height = 5)
setwd("~/Desktop/2016/Data_science/Kaggle/Kaggle-Competition-Titanic")
```

Load the data sets:

```{r}
training <- read.csv("train.csv", stringsAsFactors = FALSE, na.strings = "")
testing <- read.csv("test.csv", stringsAsFactors = FALSE,na.strings = "")
```

Partition the training set into:

- training: train different models
- tune.test.set: initial out of the box performance

```{r,results='markup'}
library(caret)
set.seed(1234)
InTrain <- createDataPartition(y=training$Survived,p = 0.7,list = FALSE)

tune.test.set <- training[-InTrain,]
training <- training[InTrain,]

```



Summarize the training data set:
```{r}
summary(training)
table(training$Sex)
table(training$Cabin)
table(training$Embarked)
```


# Basic preprocessing and EDA (all processing performed in the building set and exactly applied to tune.testing,validation, and final_testing sets)

## Generate factor (categorical variables)
```{r}
training <- transform(training,Survived = factor(Survived), Pclass = factor(Pclass),
          Sex = factor(Sex),SibSp = factor(SibSp), Parch = factor(Parch))
tune.test.set <- transform(tune.test.set,Survived = factor(Survived), Pclass = factor(Pclass),Sex = factor(Sex),SibSp = factor(SibSp), Parch = factor(Parch))

testing <- transform(testing, Pclass = factor(Pclass),
          Sex = factor(Sex),SibSp = factor(SibSp), Parch = factor(Parch))

```

## Remove the passenger ID column from the training sets.

```{r}
library(dplyr)
training <- dplyr::select(training,-PassengerId)
tune.test.set <- dplyr::select(tune.test.set,-PassengerId)
```

# Investigate the missing values

```{r}
training.na <- as.data.frame(is.na(training));names(training.na) <- names(training)
apply(training.na,2,sum)
```

Missing values appear in 3 variables; Age, Cabin and Embarked.

### Cabin feature: more than 75% is missing

From the available observations, we can infer that the first letter actually presents the cabin section.

Extract the first letter from the available ones and test if they have any predictive value:

```{r}
library(ggplot2); library(dplyr)
Cabin.letter <-substr(training$Cabin[!training.na$Cabin],1,1)
Cabin.survival <- training$Survived[!training.na$Cabin]
Cabin.Pclass <- training$Pclass[!training.na$Cabin]
qplot(x = factor(Cabin.letter), fill = Cabin.survival)+scale_fill_manual(values = c("red","navy"))+theme_bw()
```
We notice that this feature has some predictive value. 

We check if the cabin relates with the Pclass:
```{r}
qplot(x = factor(Cabin.letter), fill = Cabin.Pclass)+scale_fill_manual(values = c("red","navy","green"))+theme_bw()
```
We indeed notice that Cabin letters A,B,C are absolutely first class and therefore can be imputed from the Pclass variable. D and E are also more likely to be in 1st class. Gs are all coming from the 3rd Class. 

We can also check if fare relates with the cabin letter:
```{r}
Cabin.Fare <- training$Fare[!training.na$Cabin]
qplot(x = factor(Cabin.letter), y=Cabin.Fare, color = Cabin.survival)+theme_bw()
```
The relationship between Fare and Cabin Letter is not so dramatic to allow some imputation. 

The problem with imputing Cabin feature with Pclass is that we don't know whether the missing variables are MCAR (Missing Completely at Random) or whether there is a relationship between the reason they are missing and the outcome (Survival).

Therefore, it would be more sensible to drop this variable and don't use in building our classifiers.

####Remove Cabin feature from all sets:

```{r}
training <- dplyr::select(training, - Cabin)
tune.test.set <- dplyr::select(tune.test.set, -Cabin)
testing <- dplyr::select(testing, -Cabin)
```

## Age feature: ~ 20% missing data

One intuitive imputation potential could be comparing the Age with SibSp feature:

```{r}
qplot(x = SibSp, y = Age, color = Survived, data = training)+
       theme_bw()
  
```
We notice that as the SibSp increases, the age group decreases.
```{r}
ggplot(data = training, aes(x = Age, fill= Survived))+
        geom_histogram(bins = 40)+facet_grid(. ~ SibSp)+ scale_fill_manual(values = c("red","navy"))+
        theme_bw()
```
Most of the Age distribution is having either no Spouses or siblings or only 1.  For the 1 siblings/spouses group the mean age is higher. In both cases Age is appromated by normal distribution.

It would be sensible to impute Age by random gaussian imputation using the mean and standard deviation of individual SibSp levels.



```{r}
#Exploration by pairs plot:
pairs(Survived ~ Age+ SibSp+Parch+Fare,pch =19, cex = 0.4,data=training,
      col= ifelse(training$Survived == 1, "navy","red"))

# Clearly less people survived from the 3rd class
table(training$Survived,training$Pclass)

table(training$Survived, training$Embarked)

# Clearly more Females survived
table(training$Survived,training$Sex)



# Consistent with the Class ~ Survival relationship
boxplot(log(Fare) ~ Survived, data = training)


library(ggplot2)
ggplot(aes(x = SibSp, fill = factor(Survived)), data = training)+
        geom_bar(stat = "count")+
        theme_bw()

ggplot(aes(x = Parch, fill = factor(Survived)), data = training)+
        geom_bar(stat = "count")+
        theme_bw()

boxplot(SibSp ~ Survived, data = training)
boxplot(Parch ~ Survived, data = training)
```

#Feature Engineering:






STEP: Generate Dummy Variables for Sex, Pclass
Better to perform this step at the very end for all categorical variables.

```{r}
library(caret)
dummies <- dummyVars(Survived ~ Sex + factor(Pclass), data = training)

# Add the dummy variables to both training and test data set:
training <- cbind(training, predict(dummies,newdata = training))
testing <- cbind(testing, predict(dummies,newdata = testing))
```

