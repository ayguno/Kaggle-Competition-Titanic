---
title: "This is just the scratchpad for the analysis not the final report"
author: "Ozan Aygun"
date: "5/7/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results = "markup", fig.align = "center",
                      fig.width = 5, fig.height = 5)
setwd("~/Desktop/2016/Data_science/Kaggle/Kaggle-Competition-Titanic")
```

Load the data sets:

```{r}
training <- read.csv("train.csv", stringsAsFactors = FALSE, na.strings = "")
testing <- read.csv("test.csv", stringsAsFactors = FALSE,na.strings = "")
```

Partition the training set into:

- training: train different models
- tune.test.set: initial out of the box performance

```{r,results='markup'}
library(caret)
set.seed(1234)
InTrain <- createDataPartition(y=training$Survived,p = 0.7,list = FALSE)

tune.test.set <- training[-InTrain,]
training <- training[InTrain,]

```



Summarize the training data set:
```{r}
summary(training)
table(training$Sex)
table(training$Cabin)
table(training$Embarked)
```


# Basic preprocessing and EDA (all processing performed in the building set and exactly applied to tune.testing,validation, and final_testing sets)


```{r}
#Exploration by pairs plot:
pairs(Survived ~ Age+ SibSp+Parch+Fare,pch =19, cex = 0.4,data=training,
      col= ifelse(training$Survived == 1, "navy","red"))

# Clearly less people survived from the 3rd class
table(training$Survived,training$Pclass)

table(training$Survived, training$Embarked)

# Clearly more Females survived
table(training$Survived,training$Sex)



# Consistent with the Class ~ Survival relationship
boxplot(log(Fare) ~ Survived, data = training)


library(ggplot2)
ggplot(aes(x = SibSp, fill = factor(Survived)), data = training)+
        geom_bar(stat = "count")+
        theme_bw()

ggplot(aes(x = Parch, fill = factor(Survived)), data = training)+
        geom_bar(stat = "count")+
        theme_bw()

boxplot(SibSp ~ Survived, data = training)
boxplot(Parch ~ Survived, data = training)
```

## Generate factor (categorical variables)
```{r}
training <- transform(training,Survived = factor(Survived), Pclass = factor(Pclass),
          Sex = factor(Sex),SibSp = factor(SibSp), Parch = factor(Parch), Embarked = factor(Embarked))
tune.test.set <- transform(tune.test.set,Survived = factor(Survived), Pclass = factor(Pclass),Sex = factor(Sex),SibSp = factor(SibSp), Parch = factor(Parch), Embarked = factor(Embarked))

testing <- transform(testing, Pclass = factor(Pclass),
          Sex = factor(Sex),SibSp = factor(SibSp), Parch = factor(Parch), Embarked = factor(Embarked))

```

## Remove the passenger ID column from the training sets.

```{r}
library(dplyr)
training <- dplyr::select(training,-PassengerId)
tune.test.set <- dplyr::select(tune.test.set,-PassengerId)
```

# Investigate the missing values

```{r}
training.na <- as.data.frame(is.na(training));names(training.na) <- names(training)
apply(training.na,2,sum)
```

Missing values appear in 3 variables; Age, Cabin and Embarked.

### Cabin feature: more than 75% is missing

From the available observations, we can infer that the first letter actually presents the cabin section.

Extract the first letter from the available ones and test if they have any predictive value:

```{r}
library(ggplot2); library(dplyr)
Cabin.letter <-substr(training$Cabin[!training.na$Cabin],1,1)
Cabin.survival <- training$Survived[!training.na$Cabin]
Cabin.Pclass <- training$Pclass[!training.na$Cabin]
qplot(x = factor(Cabin.letter), fill = Cabin.survival)+scale_fill_manual(values = c("red","navy"))+theme_bw()
```
We notice that this feature has some predictive value. 

We check if the cabin relates with the Pclass:
```{r}
qplot(x = factor(Cabin.letter), fill = Cabin.Pclass)+scale_fill_manual(values = c("red","navy","green"))+theme_bw()
```
We indeed notice that Cabin letters A,B,C are absolutely first class and therefore can be inferred from the Pclass variable. D and E are also more likely to be in 1st class. Gs are all coming from the 3rd Class. 

We can also check if fare relates with the cabin letter:
```{r}
Cabin.Fare <- training$Fare[!training.na$Cabin]
qplot(x = factor(Cabin.letter), y=Cabin.Fare, color = Cabin.survival)+theme_bw()
```
The relationship between Fare and Cabin Letter is not so dramatic to allow some imputation. 

The problem with imputing Cabin feature from Pclass is that we don't know whether the missing variables are MCAR (Missing Completely at Random) or whether there is a relationship between the reason they are missing and the outcome (Survival).

Therefore, it would be more sensible to drop this variable and don't use in building our classifiers.

####Remove Cabin feature from all sets:

```{r}
training <- dplyr::select(training, - Cabin)
tune.test.set <- dplyr::select(tune.test.set, -Cabin)
testing <- dplyr::select(testing, -Cabin)
```

## Age feature: ~ 20% missing data

One intuitive imputation potential could be comparing the Age with SibSp feature:

```{r}
qplot(x = SibSp, y = Age, color = Survived, data = training)+
       theme_bw()
  
```
We notice that as the SibSp increases, the age group decreases. 
```{r}
ggplot(data = training, aes(x = Age, fill= Survived))+
        geom_histogram(bins = 40)+facet_grid(. ~ SibSp)+ scale_fill_manual(values = c("red","navy"))+
        theme_bw()
```
Most of the Age distribution is having either no Spouses or siblings or only 1.  For the 1 siblings/spouses group the mean age is higher. In both cases Age is appromated by normal distribution. The problem with SibSp is that some of the factor levels are only present in the observations where Age is missing, making this predictor unbalanced across the missing and complete cases.

It would be also interesting to explore gender differences when considering Age:
```{r}
ggplot(data = training, aes(x = Age, fill= Survived))+
        geom_histogram(bins = 40)+facet_grid(. ~ Sex)+ scale_fill_manual(values = c("red","navy"))+
        theme_bw()
```
How about the Age distribution in different passenger classes? (Pclass):

```{r}
ggplot(data = training, aes(x = Age, fill= Survived))+
        geom_histogram(bins = 40)+facet_grid(. ~ Pclass)+ scale_fill_manual(values = c("red","navy"))+
        theme_bw()
training %>% group_by(Pclass,Survived) %>% summarise(mean(Age,na.rm=T))
```
This is quite interesting! In all passenger classes, the mean age of the survived passengers is lower than those passed away. We also notice that the mean age decreases and the Class number increases, i.e: older passengers are in the better classes on average. Therefore, Pclass would also be include in the imputation model.

It would be therefore sensible to impute Age by random gaussian imputation using the mean and standard deviation of individual factor levels of these predictors. We will include Sex in this model to account for gender-specific differences in Age, as well as Pclass to account for the interesting seperation of Age by Passenger Class we noted above. In order to do this more rigorously, we can first fit a linear model with the existing Age , Sex  and Pclass  data:

##### Age ~  Sex + Pclass + e (random gaussian error)

```{r}
lmAge = lm(Age ~ Sex + Pclass, data = training, na.action = "na.omit")
summary(lmAge)
par(mfrow = c(2,2))
plot(lmAge)[1]
plot(lmAge)[2]
plot(lmAge)[3]
plot(lmAge)[4]
```
This model is just OK, but we don't need the perfect model for this type of imputation. Nice to see that both variance and normality assumptions of the model holds and all levels of the covariates have significant impact on the mean outcome in the presence of each other. This would give us a good estimation for the missing values of Age.

Using the model to impute missing values of Age:

```{r}
training$Age[is.na(training$Age)] = predict(lmAge, newdata = training[is.na(training$Age),])
tune.test.set$Age[is.na(tune.test.set$Age)] = predict(lmAge, newdata = tune.test.set[is.na(tune.test.set$Age),])
testing$Age[is.na(testing$Age)] = predict(lmAge, newdata = testing[is.na(testing$Age),])

```
Note that we use the same model object we derived from the training data set to impute the missing values of Age for all data sets. This will prevent us from overfitting to the test data set.

Re-investigate the missing values:
```{r}
training.na <- as.data.frame(is.na(training));names(training.na) <- names(training)
apply(training.na,2,sum)

tune.testing.na <- as.data.frame(is.na(tune.test.set));names(tune.testing.na) <- names(tune.test.set)
apply(tune.testing.na ,2,sum)

testing.na <- as.data.frame(is.na(testing));names(testing.na) <- names(testing)
apply(testing.na ,2,sum)

```
It appears that only one case is left missing in each of the data sets. We will consider this as random missingness and remove in each data set:

```{r}
training <- training[complete.cases(training),]
tune.test.set <- tune.test.set[complete.cases(tune.test.set),]
testing <- testing[complete.cases(testing),]
```








#Feature Engineering:






STEP: Generate Dummy Variables for Sex, Pclass
Better to perform this step at the very end for all categorical variables.

```{r}
library(caret)
dummies <- dummyVars(Survived ~ Sex + factor(Pclass), data = training)

# Add the dummy variables to both training and test data set:
training <- cbind(training, predict(dummies,newdata = training))
testing <- cbind(testing, predict(dummies,newdata = testing))
```

